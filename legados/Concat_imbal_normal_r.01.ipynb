{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The database is composed by several CSV (Comma-Separated Values) files, each one with 8 columns, one column for each sensor, according to:\n",
    "\n",
    "column 1 tachometer signal that allows to estimate rotation frequency;\n",
    "\n",
    "columns 2 to 4 underhang bearing accelerometer (axial, radiale tangential direction);\n",
    "\n",
    "columns 5 to 7 overhang bearing accelerometer (axial, radiale tangential direction);\n",
    "\n",
    "column 8 microphone.\n",
    "\n",
    "source: https://www02.smt.ufrj.br/~offshore/mfs/page_01.html\n",
    "\n",
    "According to the description of the columns there are not one two radial orthogonal accelerometers. Thus, it is not possible to observe the movement orbit of the rotating machine.\n",
    "\n",
    "On the other hand, perhaps the tangential accelerometer is also moving radially, therefore orthogonal to the radial accelerometer.\n",
    "\n",
    "Soft-DTW é uma função de perda diferenciável usada em análise de séries temporais, baseada no Dynamic Time Warping (DTW). Permite comparar séries de tamanhos variáveis, é robusta a deslocamentos e dilatações no tempo, e pode ser usada em aprendizado de máquina para tarefas como média, clustering e previsão.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Instalação do soft-DTW:\n",
    "\n",
    "1 - activate a venv\n",
    "2 - pip install --upgrade pip setuptools wheel\n",
    "3 - pip install numpy cython\n",
    "4 - pip install soft-dtw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-15T19:08:35.694519Z",
     "iopub.status.busy": "2025-06-15T19:08:35.693693Z",
     "iopub.status.idle": "2025-06-15T19:09:08.591348Z",
     "shell.execute_reply": "2025-06-15T19:09:08.590155Z",
     "shell.execute_reply.started": "2025-06-15T19:08:35.694483Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# pip install soft-dtw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-15T19:09:15.259346Z",
     "iopub.status.busy": "2025-06-15T19:09:15.258425Z",
     "iopub.status.idle": "2025-06-15T19:09:23.131538Z",
     "shell.execute_reply": "2025-06-15T19:09:23.130557Z",
     "shell.execute_reply.started": "2025-06-15T19:09:15.259303Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: soft-dtw\n",
      "Version: 0.1.6\n",
      "Summary: Python implementation of soft-DTW\n",
      "Home-page: https://github.com/mblondel/soft-dtw/\n",
      "Author: \n",
      "Author-email: \n",
      "License: Simplified BSD\n",
      "Location: d:\\IFSP\\Matematica - Aulas\\Codes\\math\\Lib\\site-packages\n",
      "Requires: chainer, cython, numpy, scikit-learn, scipy\n",
      "Required-by: \n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip show soft-dtw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-06-15T19:09:29.023819Z",
     "iopub.status.busy": "2025-06-15T19:09:29.023456Z",
     "iopub.status.idle": "2025-06-15T19:09:29.287865Z",
     "shell.execute_reply": "2025-06-15T19:09:29.287175Z",
     "shell.execute_reply.started": "2025-06-15T19:09:29.023784Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "# import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "# from tensorflow.keras import layers, models\n",
    "# from tensorflow.keras.utils import plot_model\n",
    "from sdtw import SoftDTW\n",
    "from sdtw.distance import SquaredEuclidean\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1 - df_desbalanceado_20g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_20g = \"C:/Files/mafaulda_full/overhang/ball_fault/20g\"\n",
    "# df_normal = \"C:/Files/mafaulda_full/normal\"\n",
    "df_unbalance_20g = \"C:/Files/mafaulda_bas/imbal_small/20g\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1 - Concatenação:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-15T19:09:33.878060Z",
     "iopub.status.busy": "2025-06-15T19:09:33.877023Z",
     "iopub.status.idle": "2025-06-15T19:09:42.685234Z",
     "shell.execute_reply": "2025-06-15T19:09:42.684322Z",
     "shell.execute_reply.started": "2025-06-15T19:09:33.878024Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__Dataframe combinado (df_20g_concat) ___\n",
      "         0         1         2       3\n",
      "0 -0.53339  0.001064  0.000731 -2.6298\n",
      "1 -0.52115 -0.004112 -0.002363 -2.6211\n",
      "2 -0.52931  0.027923  0.026279 -2.5818\n",
      "3 -0.53356  0.026850  0.030906 -2.6547\n",
      "4 -0.51701  0.024686  0.024161 -2.5422\n",
      "\n",
      "--- Tipos de dados (dtypes) ---\n",
      "0    float64\n",
      "1    float64\n",
      "2    float64\n",
      "3    float64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Lista para armazenar os DataFrames\n",
    "\n",
    "dataframes = []\n",
    "\n",
    "# Verifica se o caminho fornecido é um diretório válido\n",
    "if os.path.isdir(df_unbalance_20g):\n",
    "    # Iterar pelos arquivos no diretório\n",
    "    for filename in os.listdir(df_unbalance_20g):\n",
    "        if filename.endswith(\".csv\"): \n",
    "            file_path = os.path.join(df_unbalance_20g, filename)\n",
    "            \n",
    "            try:\n",
    "                # Lendo o arquivo CSV, pulando a primeira linha (cabeçalho).\n",
    "                # O parâmetro skiprows=1 é a chave para resolver o problema do 'object' dtype.\n",
    "                df = pd.read_csv(file_path, sep=',', header=None, skiprows=1)\n",
    "                dataframes.append(df)\n",
    "            except Exception as e:\n",
    "                print(f\"Não foi possível ler o arquivo {filename}: {e}\")\n",
    "\n",
    "\n",
    "    if dataframes:\n",
    "        #Concatenando os dataframes em um único:\n",
    "        df_unbalance_20g_concat = pd.concat(dataframes, ignore_index=True)\n",
    "\n",
    "        # Mostrando as primeiras linhas e tipos de dados:\n",
    "        print(\"__Dataframe combinado (df_20g_concat) ___\")\n",
    "        print(df_unbalance_20g_concat.head())\n",
    "        print(\"\\n--- Tipos de dados (dtypes) ---\")\n",
    "        print(df_unbalance_20g_concat.dtypes)\n",
    "    else:\n",
    "        print(\"Não houve leitura de arquivos\")\n",
    "else:\n",
    "    print(f\"diretório df_desbalanceado_20g não encontrado: {df_unbalance_20g}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Supondo ultima coluna como rotulos ou classes (y) e as demais como features (X):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-15T19:09:54.485677Z",
     "iopub.status.busy": "2025-06-15T19:09:54.484896Z",
     "iopub.status.idle": "2025-06-15T19:09:54.490322Z",
     "shell.execute_reply": "2025-06-15T19:09:54.489369Z",
     "shell.execute_reply.started": "2025-06-15T19:09:54.485567Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X df_unbalance_20g:\n",
      "          0         1         2\n",
      "0 -0.53339  0.001064  0.000731\n",
      "1 -0.52115 -0.004112 -0.002363\n",
      "2 -0.52931  0.027923  0.026279\n",
      "3 -0.53356  0.026850  0.030906\n",
      "4 -0.51701  0.024686  0.024161 \n",
      " X dtypes:\n",
      " 0    float64\n",
      "1    float64\n",
      "2    float64\n",
      "dtype: object\n",
      "y df_unbalance_20g:\n",
      " 0   -2.6298\n",
      "1   -2.6211\n",
      "2   -2.5818\n",
      "3   -2.6547\n",
      "4   -2.5422\n",
      "Name: 3, dtype: float64 \n",
      " y dtypes:\n",
      " float64\n",
      "--------------------------------------\n",
      "X shape(df_unbalance_20g): (12249951, 3)\n",
      "y shape(df_unbalance_20g): (12249951,)\n",
      "--------------------------------------\n",
      "ooooooooooooooooooooooooooooooooooooo\n"
     ]
    }
   ],
   "source": [
    "\n",
    "X = df_unbalance_20g_concat.iloc[:, :-1]           # Todas as colunas, menos a última\n",
    "y = df_unbalance_20g_concat.iloc[:, -1]            # Apenas a última coluna\n",
    "\n",
    "\n",
    "print(\"X df_unbalance_20g:\\n\", X.head(), \"\\n X dtypes:\\n\", X.dtypes)\n",
    "print(\"y df_unbalance_20g:\\n\", y.head(), \"\\n y dtypes:\\n\", y.dtypes)\n",
    "print('--------------------------------------')\n",
    "print(\"X shape(df_unbalance_20g):\", X.shape)\n",
    "print(\"y shape(df_unbalance_20g):\", y.shape)\n",
    "print('--------------------------------------')\n",
    "print('ooooooooooooooooooooooooooooooooooooo')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2 - Normalização:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- É um comportamento esperado do pandas. Essa linha não se refere a uma coluna específica do seu DataFrame. Ela descreve o tipo de dados da própria lista de tipos que está sendo exibida. Como a lista contém vários objetos de tipo float64 e outros, o pandas a classifica como uma série de tipo object.\n",
    "- fit (Ajustar/Aprender): A primeira parte, fit, \"olha\" para cada coluna (cada sensor), calcula a média (μ) e o desvio padrão (σ) daquela coluna específica, aprendendo os parâmetros de distribuição dos dados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-15T19:10:04.991145Z",
     "iopub.status.busy": "2025-06-15T19:10:04.990550Z",
     "iopub.status.idle": "2025-06-15T19:10:04.995406Z",
     "shell.execute_reply": "2025-06-15T19:10:04.994456Z",
     "shell.execute_reply.started": "2025-06-15T19:10:04.991109Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1. Aplicando a normalização (StandardScaler) aos dados de X...\n"
     ]
    }
   ],
   "source": [
    "# Função para normalizar os dados. preprocess_data padroniza os dados antes de entregá-los ao modelo para tr\n",
    "\n",
    "print(\"\\n1. Aplicando a normalização (StandardScaler) aos dados de X...\")\n",
    "def preprocess_data(data_to_scale):                                  # X  é o conjunto de dados de entrada (as leituras dos 8 sensores de vibração\n",
    "    print(\"   'X_scaled' foi criado com sucesso!\")\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled_out = scaler.fit_transform(X)\n",
    "    print(f\"   Formato do X_scaled: {X_scaled.shape}, Tipo: {type(X_scaled)}\")\n",
    "    print('-----------------------------------------')\n",
    "    \n",
    "    # VISUALIZAR OS DADOS NORMALIZADOS\n",
    "    print(\"\\n2. Gerando gráficos para visualização...\")\n",
    "    return scaled_data_out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 - Análise do sinal do tacômetro:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-15T19:10:13.114402Z",
     "iopub.status.busy": "2025-06-15T19:10:13.114021Z",
     "iopub.status.idle": "2025-06-15T19:10:54.037770Z",
     "shell.execute_reply": "2025-06-15T19:10:54.036938Z",
     "shell.execute_reply.started": "2025-06-15T19:10:13.114367Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_scaled' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m sensor_a_visualizar = \u001b[32m0\u001b[39m \n\u001b[32m      2\u001b[39m raw_tac_signal = X.iloc[:, sensor_a_visualizar].values\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m scaled_tac_signal = \u001b[43mX_scaled\u001b[49m[:, sensor_a_visualizar]\n\u001b[32m      5\u001b[39m \u001b[38;5;66;03m# --- Gráfico 1: Comparação do Sinal no Tempo ---\u001b[39;00m\n\u001b[32m      6\u001b[39m plt.figure(figsize=(\u001b[32m16\u001b[39m, \u001b[32m8\u001b[39m))\n",
      "\u001b[31mNameError\u001b[39m: name 'X_scaled' is not defined"
     ]
    }
   ],
   "source": [
    "sensor_a_visualizar = 0 \n",
    "raw_tac_signal = X.iloc[:, sensor_a_visualizar].values\n",
    "scaled_tac_signal = X_scaled[:, sensor_a_visualizar]\n",
    "\n",
    "# --- Gráfico 1: Comparação do Sinal no Tempo ---\n",
    "plt.figure(figsize=(16, 8))\n",
    "\n",
    "# Gráfico do sinal original\n",
    "plt.subplot(2, 1, 1)\n",
    "plt.plot(raw_tac_signal, label=f'Sinal Original Tacômetro (Sensor {sensor_a_visualizar})', color='blue', alpha=0.4)\n",
    "plt.title(f'Sinal Original do Tacômetro {sensor_a_visualizar}', fontsize=10)\n",
    "plt.ylabel('Amplitude Original do Tacômetro', fontsize=10)\n",
    "plt.legend()\n",
    "plt.grid(True, linestyle='--', alpha=0.4)\n",
    "\n",
    "# Gráfico do sinal normalizado\n",
    "plt.subplot(2, 1, 2)\n",
    "plt.plot(scaled_tac_signal, label=f'Sinal Normalizado (Tacômetro {sensor_a_visualizar})', color='red', alpha=0.4)\n",
    "plt.title(f'Sinal Normalizado do Tacômetro {sensor_a_visualizar} (Média ≈ 0, Desvio Padrão = 1)', fontsize=10)\n",
    "plt.xlabel('Amostra no Tempo', fontsize=10)\n",
    "plt.ylabel('Amplitude Normalizada do Tacômetro', fontsize=10)\n",
    "plt.legend()\n",
    "plt.grid(True, linestyle='--', alpha=0.4)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-15T19:11:02.867947Z",
     "iopub.status.busy": "2025-06-15T19:11:02.867240Z",
     "iopub.status.idle": "2025-06-15T19:11:51.945362Z",
     "shell.execute_reply": "2025-06-15T19:11:51.944497Z",
     "shell.execute_reply.started": "2025-06-15T19:11:02.867911Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# --- Gráfico 2: Comparação da Distribuição dos Dados (Histograma) ---\n",
    "plt.figure(figsize=(16, 6))\n",
    "\n",
    "# Histograma do sinal original\n",
    "plt.subplot(1, 2, 1)\n",
    "sns.histplot(raw_tac_signal, kde=True, color='blue', bins=50)\n",
    "plt.title(f'Distribuição Original do Tacômetro (Sensor {sensor_a_visualizar})', fontsize=10)\n",
    "plt.xlabel('Tempo (amostragem)', fontsize=10)\n",
    "plt.ylabel('Amplitude original (1x106)', fontsize=10)\n",
    "plt.grid(True, linestyle='--', alpha=0.4)\n",
    "\n",
    "# Histograma do sinal normalizado\n",
    "plt.subplot(1, 2, 2)\n",
    "sns.histplot(scaled_tac_signal, kde=True, color='red', bins=50)\n",
    "plt.title(f'Distribuição Normalizada do Tacômetro (Sensor {sensor_a_visualizar})', fontsize=10)\n",
    "plt.xlabel('Tempo (amostragem) Normalizado', fontsize=10)\n",
    "plt.ylabel('Amplitude normalizada (1x106)', fontsize=10)\n",
    "plt.grid(True, linestyle='--', alpha=0.4)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nVisualização concluída.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-15T19:12:59.774080Z",
     "iopub.status.busy": "2025-06-15T19:12:59.773375Z",
     "iopub.status.idle": "2025-06-15T19:13:49.362158Z",
     "shell.execute_reply": "2025-06-15T19:13:49.361219Z",
     "shell.execute_reply.started": "2025-06-15T19:12:59.774047Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# 2. VISUALIZAR OS DADOS NORMALIZADOS (COM ZOOM)\n",
    "print(\"\\n2. Gerando gráficos para visualização...\")\n",
    "\n",
    "# Escolha qual coluna do sensor (0 a 7) você quer visualizar\n",
    "sensor_a_visualizar = 0 \n",
    "# Define o número de amostras para o \"zoom\" para melhor visualização\n",
    "# num_amostras_plot = 1500\n",
    "num_amostras_plot = 15000\n",
    "\n",
    "# Pega todos os dados da coluna do sensor escolhido\n",
    "raw_tac_signal = X.iloc[:, sensor_a_visualizar].values\n",
    "scaled_tac_signal = X_scaled[:, sensor_a_visualizar]\n",
    "\n",
    "# --- Gráfico 1: Comparação do Sinal no Tempo (com zoom) ---\n",
    "plt.figure(figsize=(16, 8))\n",
    "\n",
    "# Gráfico do sinal original (zoom)\n",
    "plt.subplot(2, 1, 1)\n",
    "# Plota apenas as primeiras 'num_amostras_plot' amostras para dilatar o eixo X\n",
    "plt.plot(raw_tac_signal[:num_amostras_plot], label=f'Sinal Original (Tacômetro {sensor_a_visualizar})', color='blue', alpha=0.4)\n",
    "plt.title(f'Sinal Original do Tacômetror {sensor_a_visualizar} (Zoom nas primeiras {num_amostras_plot} amostras)', fontsize=10)\n",
    "plt.ylabel('Amplitude Original (1x106)', fontsize=10)\n",
    "plt.legend()\n",
    "plt.grid(True, linestyle='--', alpha=0.6)\n",
    "\n",
    "# Gráfico do sinal normalizado (zoom)\n",
    "plt.subplot(2, 1, 2)\n",
    "# Plota apenas as primeiras 'num_amostras_plot' amostras\n",
    "plt.plot(scaled_tac_signal[:num_amostras_plot], label=f'Sinal Normalizado (Tacômetro {sensor_a_visualizar})', color='red', alpha=0.4)\n",
    "plt.title(f'Sinal Normalizado do Tacômetro {sensor_a_visualizar} (Média ≈ 0, Desvio Padrão = 1)', fontsize=10)\n",
    "plt.xlabel(f'Amostras (0 a {num_amostras_plot})', fontsize=10)\n",
    "plt.ylabel('Amplitude Normalizada (1x106)', fontsize=10)\n",
    "plt.legend()\n",
    "plt.grid(True, linestyle='--', alpha=0.6)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# --- Gráfico 2: Comparação da Distribuição dos Dados (usando o sinal completo) ---\n",
    "plt.figure(figsize=(16, 6))\n",
    "\n",
    "# Histograma do sinal original\n",
    "plt.subplot(1, 2, 1)\n",
    "sns.histplot(raw_tac_signal, kde=True, color='blue', bins=50)\n",
    "plt.title(f'Distribuição do Sinal Original (Tacômetro {sensor_a_visualizar})', fontsize=10)\n",
    "plt.xlabel('Amplitude', fontsize=10)\n",
    "plt.ylabel('Contagem', fontsize=10)\n",
    "plt.grid(True, linestyle='--', alpha=0.5)\n",
    "\n",
    "# Histograma do sinal normalizado\n",
    "plt.subplot(1, 2, 2)\n",
    "sns.histplot(scaled_tac_signal, kde=True, color='red', bins=50)\n",
    "plt.title(f'Distribuição do Sinal Normalizado (Tacômetro {sensor_a_visualizar})', fontsize=10)\n",
    "plt.xlabel('Amplitude Normalizada (1x106)', fontsize=10)\n",
    "plt.ylabel('Contagem', fontsize=10)\n",
    "plt.grid(True, linestyle='--', alpha=0.5)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nVisualização concluída.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- \"Contagem\" significa a frequência ou o número de vezes que um determinado valor de amplitude ocorreu no seu conjunto de dados.\n",
    "- A linha azul contínua (chamada de KDE - Kernel Density Estimate) é uma versão suavizada do histograma. O pico dessa linha mostra qual é o valor de amplitude mais comum em todo o conjunto de dados."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Desbalanceamento com 20g"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fazendo uma análise do sinal do acelerômetro com 20g de desbalanceamento:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Análise no Domínio do Tempo (Sincronização e Visualização): Primeiro, vamos plotar o sinal de vibração do acelerômetro contra uma base de tempo real em segundos e, ao mesmo tempo, usar o tacômetro para calcular a rotação exata da máquina (RPM) naquele ensaio.\n",
    "- Análise no Domínio da Frequência (objetivo): Em seguida, usaremos a Transformada Rápida de Fourier (FFT) para converter o sinal de vibração do domínio do tempo para o domínio da frequência. É aqui que a \"assinatura\" do desbalanceamento se tornará visível e quantificável.\n",
    "- o sinal do tacômetro nos dá a base de tempo (a rotação da máquina), e o sinal do acelerômetro nos dá a vibração.\n",
    "- A categoria imbalance 20g já foi carregada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-15T19:15:57.028621Z",
     "iopub.status.busy": "2025-06-15T19:15:57.028006Z",
     "iopub.status.idle": "2025-06-15T19:15:57.032795Z",
     "shell.execute_reply": "2025-06-15T19:15:57.031900Z",
     "shell.execute_reply.started": "2025-06-15T19:15:57.028583Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "COLUNA_TACOMETRO = 0\n",
    "# Coluna do acelerômetro radial do overhang (sexta coluna, índice 5)\n",
    "COLUNA_ACELEROMETRO = 5 \n",
    "\n",
    "# Parâmetros do dataset MAFAULDA\n",
    "TAXA_AMOSTRAGEM = 50000  # 50 kHz\n",
    "DURACAO_ENSAIO_S = 5    # 5 segundos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-15T19:18:32.382530Z",
     "iopub.status.busy": "2025-06-15T19:18:32.381441Z",
     "iopub.status.idle": "2025-06-15T19:18:32.390815Z",
     "shell.execute_reply": "2025-06-15T19:18:32.389707Z",
     "shell.execute_reply.started": "2025-06-15T19:18:32.382478Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# --- FUNÇÃO PARA ANÁLISE E PLOTAGEM ---\n",
    "# --- FUNÇÃO PARA ANÁLISE E PLOTAGEM ---\n",
    "def analisar_sinal_temporal(caminho_arquivo, nome_condicao):\n",
    "    \"\"\"\n",
    "    Carrega, analisa e plota o sinal de vibração e calcula o RPM a partir do tacômetro.\n",
    "    \"\"\"\n",
    "    if not os.path.exists(caminho_arquivo):\n",
    "        print(f\"AVISO: Arquivo não encontrado: {caminho_arquivo}\")\n",
    "        return None, None\n",
    "\n",
    "    print(f\"\\n--- Analisando Condição: {nome_condicao} ---\")\n",
    "    \n",
    "    # Carrega o arquivo CSV, pulando a linha de cabeçalho se houver\n",
    "    df = pd.read_csv(caminho_arquivo, header=None, skiprows=1)\n",
    "\n",
    "    # Extrai os sinais do acelerômetro e do tacômetro\n",
    "    sinal_acelerometro = df.values\n",
    "    sinal_tacometro = df.values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-15T19:18:35.414424Z",
     "iopub.status.busy": "2025-06-15T19:18:35.413962Z",
     "iopub.status.idle": "2025-06-15T19:18:35.443797Z",
     "shell.execute_reply": "2025-06-15T19:18:35.442585Z",
     "shell.execute_reply.started": "2025-06-15T19:18:35.414391Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sinal_tacometro' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[35], line 5\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# --- Cálculo do RPM a partir do Tacômetro ---\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# O tacômetro gera um pulso por rotação. Contamos os pulsos.\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Um pulso é detectado quando o sinal cruza um limiar (ex: valor 2.5) para cima.\u001b[39;00m\n\u001b[1;32m      4\u001b[0m limiar_pulso \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2.5\u001b[39m\n\u001b[0;32m----> 5\u001b[0m pulsos \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mwhere((\u001b[43msinal_tacometro\u001b[49m[:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m<\u001b[39m limiar_pulso) \u001b[38;5;241m&\u001b[39m (sinal_tacometro[\u001b[38;5;241m1\u001b[39m:] \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m limiar_pulso))\n\u001b[1;32m      6\u001b[0m num_pulsos \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(pulsos)\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# Calcula RPM (Rotações por Minuto)\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'sinal_tacometro' is not defined"
     ]
    }
   ],
   "source": [
    "# --- Cálculo do RPM a partir do Tacômetro ---\n",
    "# O tacômetro gera um pulso por rotação. Contamos os pulsos.\n",
    "# Um pulso é detectado quando o sinal cruza um limiar (ex: valor 2.5) para cima.\n",
    "limiar_pulso = 2.5\n",
    "pulsos = np.where((sinal_tacometro[:-1] < limiar_pulso) & (sinal_tacometro[1:] >= limiar_pulso))\n",
    "num_pulsos = len(pulsos)\n",
    "    \n",
    "# Calcula RPM (Rotações por Minuto)\n",
    "rpm = (num_pulsos / DURACAO_ENSAIO_S) * 60\n",
    "print(f\"RPM Calculado: {rpm:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-15T19:17:28.910220Z",
     "iopub.status.busy": "2025-06-15T19:17:28.909593Z",
     "iopub.status.idle": "2025-06-15T19:17:28.941916Z",
     "shell.execute_reply": "2025-06-15T19:17:28.940805Z",
     "shell.execute_reply.started": "2025-06-15T19:17:28.910170Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sinal_acelerometro' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[32], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# --- Plotagem do Sinal de Vibração ---\u001b[39;00m\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;66;03m# Cria o eixo de tempo em segundos\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m num_amostras \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[43msinal_acelerometro\u001b[49m)\n\u001b[1;32m      4\u001b[0m eixo_tempo_s \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mlinspace(\u001b[38;5;241m0\u001b[39m, DURACAO_ENSAIO_S, num_amostras)\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;66;03m# Zoom para visualizar melhor a forma de onda (primeiras 2000 amostras)\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'sinal_acelerometro' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "# --- Plotagem do Sinal de Vibração ---\n",
    "    # Cria o eixo de tempo em segundos\n",
    "num_amostras = len(sinal_acelerometro)\n",
    "eixo_tempo_s = np.linspace(0, DURACAO_ENSAIO_S, num_amostras)\n",
    "    \n",
    "    # Zoom para visualizar melhor a forma de onda (primeiras 2000 amostras)\n",
    "amostras_plot = 2000\n",
    "\n",
    "plt.figure(figsize=(15, 5))\n",
    "plt.plot(eixo_tempo_s[:amostras_plot], sinal_acelerometro[:amostras_plot], label=f'Sinal do Acelerômetro (Sensor {COLUNA_ACELEROMETRO})')\n",
    "plt.title(f'Sinal de Vibração no Domínio do Tempo - Condição: {nome_condicao} (RPM: {rpm:.0f})', fontsize=14)\n",
    "plt.xlabel('Tempo (segundos)', fontsize=12)\n",
    "plt.ylabel('Amplitude da Vibração', fontsize=12)\n",
    "plt.legend()\n",
    "plt.grid(True, linestyle='--', alpha=0.7)\n",
    "plt.show()\n",
    "    \n",
    "return sinal_acelerometro, rpm\n",
    "\n",
    "# --- EXECUÇÃO ---\n",
    "sinal_normal, rpm_normal = analisar_sinal_temporal(caminho_normal, \"Normal\")\n",
    "sinal_desbalanceado, rpm_desbalanceado = analisar_sinal_temporal(caminho_desbalanceado, \"Desbalanceamento 20g\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import EfficientNetB0\n",
    "\n",
    "def build_model(input_shape, output_size):\n",
    "    # Inicializa o modelo EfficientNetB0\n",
    "    base_model = EfficientNetB0(input_shape=input_shape, include_top=False, weights='imagenet')\n",
    "    base_model.trainable = False  # Congelar as camadas da base para transferência de aprendizado\n",
    "\n",
    "    # Adiciona camadas personalizadas ao modelo\n",
    "    model = models.Sequential([\n",
    "        base_model,\n",
    "        layers.GlobalAveragePooling2D(),  # Para agregar as características\n",
    "        layers.Dense(64, activation='relu'),  # Camada densa com ativação ReLU\n",
    "        layers.Dense(output_size, activation='softmax')  # Camada de saída com softmax para classificação\n",
    "    ])\n",
    "    \n",
    "    return model\n",
    "\n",
    "\"\"\"# Definições de entrada e número de classes\n",
    "input_shape = (32, 32, 3)  # Dimensões de entrada\n",
    "output_size = 8  # Número de classes (ajuste conforme necessário)\n",
    "\n",
    "# Construindo o modelo\n",
    "model = build_model(input_shape, output_size)\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "loss_fn = tf.keras.losses.SparseCategoricalCrossentropy()\n",
    "\n",
    "# Resumo do modelo\n",
    "model.summary()\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Função para treinar o modelo com Soft-DTW\n",
    "\"\"\"def train_model_with_soft_dtw(X_train, y_train, X_test, y_test, num_epochs=2, learning_rate=0.0001):\n",
    "    input_shape = (32, 32, 3)  # Ajuste para a entrada do modelo EfficientNetB0\n",
    "    output_size = len(np.unique(y_train))  # Número de classes\n",
    "    \n",
    "    # Convertendo dados para TensorFlow Tensors\n",
    "    X_train_tensor = tf.convert_to_tensor(X_train.reshape(-1, 32, 32, 3), dtype=tf.float32)  # Redimensionar\n",
    "    y_train_tensor = tf.convert_to_tensor(y_train, dtype=tf.int32)\n",
    "    X_test_tensor = tf.convert_to_tensor(X_test.reshape(-1, 32, 32, 3), dtype=tf.float32)  # Redimensionar\n",
    "    y_test_tensor = tf.convert_to_tensor(y_test, dtype=tf.int32)\n",
    "\n",
    "    # Inicializando o modelo\n",
    "    model = build_model(input_shape, output_size)  #Atribuindo model a uma var.\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "    loss_fn = tf.keras.losses.SparseCategoricalCrossentropy()\n",
    "\n",
    "    # Inicializando o Soft-DTW\n",
    "    soft_dtw = SoftDTW(gamma=0.1)  # Ajustar gamma conforme necessário\n",
    "\n",
    "    history = {'loss': [], 'accuracy': [], 'error': []}  # Para armazenar as perdas e acurácia\n",
    "\n",
    "    # Loop de treinamento\n",
    "    for epoch in range(num_epochs):\n",
    "        with tf.GradientTape() as tape:\n",
    "            # Predição do modelo\n",
    "            predictions = model(X_train_tensor)  # Predição\n",
    "            # Cálculo da perda de entropia cruzada\n",
    "            loss_ce = loss_fn(y_train_tensor, predictions)\n",
    "            # Cálculo da perda Soft-DTW\n",
    "            loss_dtw = soft_dtw(X_train_tensor, predictions)\n",
    "            # Perda total (entropia cruzada + Soft-DTW)\n",
    "            total_loss = loss_ce + loss_dtw\n",
    "\n",
    "        # Backpropagation\n",
    "        gradients = tape.gradient(total_loss, model.trainable_variables)\n",
    "        optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "\n",
    "        # Armazenando a perda, acurácia e erro para cada época\n",
    "        history['loss'].append(total_loss.numpy())\n",
    "        accuracy = accuracy_score(np.argmax(predictions.numpy(), axis=1), y_train)\n",
    "        history['accuracy'].append(accuracy)\n",
    "        history['error'].append(1 - accuracy)  # Calculando o erro como 1 - acurácia\n",
    "\n",
    "        print(f'Epoch {epoch+1}/{num_epochs}, Loss: {total_loss.numpy()}, Accuracy: {accuracy:.2f}, Error: {1 - accuracy:.2f}')\n",
    "\n",
    "    return history\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Definindo variáveis necessárias\n",
    "num_epochs = 2  # Número de épocas para o treinamento\n",
    "learning_rate = 0.0001  # Taxa de aprendizado\n",
    "input_shape = (32, 32, 3)  # Ajuste para a entrada do modelo EfficientNetB0\n",
    "output_size = len(np.unique(y_train))  # Número de classes\n",
    "\n",
    "# Convertendo dados para Tensores do TensorFlow\n",
    "X_train_tensor = tf.convert_to_tensor(X_train, dtype=tf.float32)  # Não há reshaping necessário\n",
    "y_train_tensor = tf.convert_to_tensor(y_train, dtype=tf.int32)\n",
    "X_test_tensor = tf.convert_to_tensor(X_test, dtype=tf.float32)  # Não há reshaping necessário\n",
    "y_test_tensor = tf.convert_to_tensor(y_test, dtype=tf.int32)\n",
    "\n",
    "# Inicializando o modelo\n",
    "model = build_model(input_shape, output_size)  # Atribuindo model a uma var.\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)  # Inicializando o otimizador\n",
    "loss_fn = tf.keras.losses.SparseCategoricalCrossentropy()  # Função de perda\n",
    "\n",
    "# Inicializando o Soft-DTW\n",
    "D = np.zeros((len(X_train_tensor), len(X_train_tensor)))  # Defina a matriz de distância corretamente\n",
    "soft_dtw = SoftDTW(gamma=0.1, D=D)  # Ajustar gamma conforme necessário\n",
    "\n",
    "# Para armazenar as perdas e acurácia\n",
    "#history = {'loss': [], 'accuracy': [], 'error': []}\n",
    "\n",
    "# Loop de treinamento\n",
    "# Loop de treinamento\n",
    "for epoch in range(num_epochs):\n",
    "    with tf.GradientTape() as tape:\n",
    "        # Predição do modelo\n",
    "        predictions = model(X_train_tensor)\n",
    "        # Cálculo da perda de entropia cruzada\n",
    "        loss_ce = loss_fn(y_train_tensor, predictions)\n",
    "        # Cálculo da perda Soft-DTW (calculando conforme necessário, não usando uma matriz D)\n",
    "        loss_dtw = soft_dtw(X_train_tensor, predictions)  # Isso deve ser implementado para calcular distâncias sob demanda\n",
    "        \n",
    "        # Calcular a perda Soft-DTW sob demanda\n",
    "        loss_dtw = sum(soft_dtw(X_train_tensor[i], predictions[i]) for i in range(len(X_train_tensor)))\n",
    "        \n",
    "        # Perda total\n",
    "        total_loss = loss_ce + loss_dtw\n",
    "\n",
    "    # Backpropagation\n",
    "    gradients = tape.gradient(total_loss, model.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "\n",
    "    # Armazenando a perda, acurácia e erro para cada época\n",
    "    history['loss'].append(total_loss.numpy())\n",
    "    accuracy = accuracy_score(np.argmax(predictions.numpy(), axis=1), y_train)\n",
    "    history['accuracy'].append(accuracy)\n",
    "    history['error'].append(1 - accuracy)\n",
    "\n",
    "    print(f'Epoch {epoch+1}/{num_epochs}, Loss: {total_loss.numpy()}, Accuracy: {accuracy:.2f}, Error: {1 - accuracy:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Definindo variáveis necessárias\n",
    "num_epochs = 2  # Número de épocas para o treinamento\n",
    "learning_rate = 0.0001  # Taxa de aprendizado\n",
    "input_shape = (32, 32, 3)  # Ajuste para a entrada do modelo EfficientNetB0\n",
    "output_size = len(np.unique(y_train))  # Número de classes\n",
    "\n",
    "# Verificando se os dados têm o formato adequado antes de redimensionar\n",
    "if X_train.shape[1] == 32 * 32 * 3:\n",
    "    X_train_tensor = tf.convert_to_tensor(X_train.reshape(-1, 32, 32, 3), dtype=tf.float32)  # Redimensionar\n",
    "else:\n",
    "    raise ValueError(f\"X_train deve ter {32 * 32 * 3} características, mas tem {X_train.shape[1]}.\")\n",
    "\n",
    "if X_test.shape[1] == 32 * 32 * 3:\n",
    "    X_test_tensor = tf.convert_to_tensor(X_test.reshape(-1, 32, 32, 3), dtype=tf.float32)  # Redimensionar\n",
    "else:\n",
    "    raise ValueError(f\"X_test deve ter {32 * 32 * 3} características, mas tem {X_test.shape[1]}.\")\n",
    "\n",
    "# Convertendo y_train e y_test para tensores\n",
    "y_train_tensor = tf.convert_to_tensor(y_train, dtype=tf.int32)\n",
    "y_test_tensor = tf.convert_to_tensor(y_test, dtype=tf.int32)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implicações de Usar training=True\n",
    "Camadas de Dropout: Se você estiver utilizando camadas de dropout no seu modelo, elas funcionarão de maneira diferente. Durante o treinamento, dropout desativa aleatoriamente uma fração das unidades (neurônios) para ajudar a prevenir overfitting. Quando training=True, algumas unidades serão desativadas, enquanto training=False garante que todas as unidades estão ativas, permitindo que o modelo faça previsões consistentes.\n",
    "\n",
    "Normalização: Se você estiver usando camadas de normalização, como Batch Normalization, a média e a variância usadas para normalizar as entradas durante o treinamento diferem das usadas durante a inferência. Com training=True, as estatísticas da mini-batch serão usadas, enquanto training=False usará as médias e variâncias acumuladas durante o treinamento.\n",
    "\n",
    "Logo, usar training=True geralmente é apropriado durante o processo de treinamento do modelo, mas não deve ser usado quando você está avaliando o modelo ou fazendo previsões. Para garantir que você obtenha resultados consistentes e previsíveis ao avaliar ou prever, deve-se usar training=False."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Avaliação no conjunto de teste\n",
    "predictions_test = model(X_test_tensor, training=False)\n",
    "predicted_classes = np.argmax(predictions_test.numpy(), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "accuracy = accuracy_score(y_test, predicted_classes)\n",
    "print(f'Accuracy on test data: {accuracy:.4f}')\n",
    "\n",
    "    # Matriz de Confusão e Relatório de Classificação\n",
    "print(\"\\nMatriz de Confusão:\")\n",
    "conf_matrix = confusion_matrix(y_test, predicted_classes)\n",
    "\n",
    "plt.figure(figsize=(10, 7))\n",
    "sns.heatmap(conf_matrix, annot=True, fmt=\"d\", cmap=\"Blues\", \n",
    "            xticklabels=np.unique(y_train), yticklabels=np.unique(y_train))\n",
    "\n",
    "plt.title(\"Matriz de Confusão\")\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"True\")\n",
    "plt.show()\n",
    "\n",
    "# Relatório de Classificação\n",
    "print(\"\\nRelatório de Classificação:\")\n",
    "print(classification_report(y_test, predicted_classes))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "\n",
    " # Pipeline principal\n",
    "# X, y = load_mafaulda_dataset()\n",
    "X, y = load_data(data_dict) \n",
    "X = preprocess_data(X)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Treinar o modelo com Soft-DTW no TensorFlow\n",
    "history = train_model_with_soft_dtw(X_train, y_train, X_test, y_test)\n",
    "\n",
    "\n",
    "    # Avaliação no conjunto de teste\n",
    "predictions_test = model(X_test_tensor)\n",
    "predicted_classes = np.argmax(predictions_test, axis=1)\n",
    "accuracy = accuracy_score(y_test, predicted_classes)\n",
    "print(f'Accuracy on test data: {accuracy:.2f}')\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "\"\"\"# Matriz de Confusão e Relatório de Classificação\n",
    "print(\"\\nMatriz de Confusão:\")\n",
    "conf_matrix = confusion_matrix(y_test, predicted_classes)\n",
    "sns.heatmap(conf_matrix, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=np.unique(y_train), yticklabels=np.unique(y_train))\n",
    "plt.title(\"Matriz de Confusão\")\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"True\")\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nRelatório de Classificação:\")\n",
    "print(classification_report(y_test, predicted_classes))\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "plt.figure(figsize=(18, 5))\n",
    "\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.plot(history['loss'], label='Perda')\n",
    "plt.title('Perda ao longo das Épocas')\n",
    "plt.xlabel('Épocas')\n",
    "plt.ylabel('Perda')\n",
    "plt.legend()\n",
    "\n",
    "    # Plotando a acurácia\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.plot(history['accuracy'], label='Acurácia')\n",
    "plt.title('Acurácia ao longo das Épocas')\n",
    "plt.xlabel('Épocas')\n",
    "plt.ylabel('Acurácia')\n",
    "plt.legend()\n",
    "\n",
    "    # Plotando o erro\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.plot(history['error'], label='Erro', color='red')\n",
    "plt.title('Erro ao longo das Épocas')\n",
    "plt.xlabel('Épocas')\n",
    "plt.ylabel('Erro')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "# Plotar as curvas de perda, acurácia e erro\n",
    "plot_history(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Avaliação no conjunto de teste\n",
    "predictions_test = model(X_test_tensor, training=False)  # Previsão no conjunto de teste\n",
    "predicted_classes = np.argmax(predictions_test.numpy(), axis=1)  # Classes previstas\n",
    "\n",
    "# Cálculo da acurácia\n",
    "accuracy = accuracy_score(y_test, predicted_classes)\n",
    "print(f'Accuracy on test data: {accuracy:.2f}')\n",
    "\n",
    "# Matriz de Confusão e Relatório de Classificação\n",
    "print(\"\\nMatriz de Confusão:\")\n",
    "conf_matrix = confusion_matrix(y_test, predicted_classes)\n",
    "\n",
    "# Visualização da Matriz de Confusão\n",
    "plt.figure(figsize=(10, 7))\n",
    "sns.heatmap(conf_matrix, annot=True, fmt=\"d\", cmap=\"Blues\", \n",
    "            xticklabels=np.unique(y_train), yticklabels=np.unique(y_train))\n",
    "plt.title(\"Matriz de Confusão\")\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"True\")\n",
    "plt.show()\n",
    "\n",
    "# Relatório de Classificação\n",
    "print(\"\\nRelatório de Classificação:\")\n",
    "print(classification_report(y_test, predicted_classes))"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 5865066,
     "isSourceIdPinned": false,
     "sourceId": 9611811,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30787,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "math",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
